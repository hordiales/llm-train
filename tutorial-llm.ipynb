{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b8e39ab",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-11T18:15:38.192191Z",
     "iopub.status.busy": "2024-06-11T18:15:38.191897Z",
     "iopub.status.idle": "2024-06-11T18:15:38.951097Z",
     "shell.execute_reply": "2024-06-11T18:15:38.950243Z"
    },
    "papermill": {
     "duration": 0.765094,
     "end_time": "2024-06-11T18:15:38.953385",
     "exception": false,
     "start_time": "2024-06-11T18:15:38.188291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/model.safetensors.index.json\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/model-00003-of-00004.safetensors\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/config.json\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/LICENSE\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/model-00001-of-00004.safetensors\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/model.py\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/USE_POLICY.md\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/tokenizer.json\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/tokenizer_config.json\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/example_text_completion.py\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/test_tokenizer.py\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/requirements.txt\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/tokenizer.py\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/model-00004-of-00004.safetensors\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/eval_details.md\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/special_tokens_map.json\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/generation.py\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/model-00002-of-00004.safetensors\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/__init__.py\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/example_chat_completion.py\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/setup.py\n",
      "/kaggle/input/llama-3/transformers/8b-chat-hf/1/generation_config.json\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873c30b2",
   "metadata": {
    "papermill": {
     "duration": 0.002017,
     "end_time": "2024-06-11T18:15:38.957953",
     "exception": false,
     "start_time": "2024-06-11T18:15:38.955936",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "https://www.datacamp.com/tutorial/llama3-fine-tuning-locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d806557",
   "metadata": {
    "papermill": {
     "duration": 0.001911,
     "end_time": "2024-06-11T18:15:38.961971",
     "exception": false,
     "start_time": "2024-06-11T18:15:38.960060",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Fine-Tuning Llama 3\n",
    "For this tutorial, we’ll fine-tune the Llama 3 8B-Chat model using the ruslanmv/ai-medical-chatbot dataset. The dataset contains 250k dialogues between a patient and a doctor. We’ll use the Kaggle Notebook to access this model and free GPUs.\n",
    "\n",
    "Setting up\n",
    "Before we launch the Kaggle Notebook, fill out the Meta download form with your Kaggle email address, then go to the Llama 3 model page on Kaggle and accept the agreement. The approval process may take one to two days.\n",
    "\n",
    "Let’s now take the following steps:\n",
    "\n",
    "# Launch the new Notebook on Kaggle, and add the Llama 3 model by clicking the + Add Input button, selecting the Models option, and clicking on the plus + button beside the Llama 3 model. After that, select the right framework, variation, and version, and add the model.\n",
    "\n",
    "Adding LLama 3 model into the Kaggle notebook\n",
    "\n",
    "# Go to the Session options and select the GPU P100 as an accelerator.\n",
    "\n",
    "Changing the accelerator to GPU P100 in Kaggle\n",
    "\n",
    "# Generate the Hugging Face and Weights & Biases token, and create the Kaggle Secrets. You can create and activate the Kaggle Secrets by going to Add-ons > Secrets > Add a new secret.\n",
    "\n",
    "Setting up secrets (environment variables)\n",
    "\n",
    "# Initiate the Kaggle session by installing all the necessary Python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dcadfdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T18:15:38.967387Z",
     "iopub.status.busy": "2024-06-11T18:15:38.967016Z",
     "iopub.status.idle": "2024-06-11T18:17:26.202489Z",
     "shell.execute_reply": "2024-06-11T18:17:26.201210Z"
    },
    "papermill": {
     "duration": 107.240959,
     "end_time": "2024-06-11T18:17:26.205025",
     "exception": false,
     "start_time": "2024-06-11T18:15:38.964066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -U transformers \n",
    "%pip install -U datasets \n",
    "%pip install -U accelerate \n",
    "%pip install -U peft \n",
    "%pip install -U trl \n",
    "%pip install -U bitsandbytes \n",
    "%pip install -U wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fba78f",
   "metadata": {
    "papermill": {
     "duration": 0.002093,
     "end_time": "2024-06-11T18:17:26.209739",
     "exception": false,
     "start_time": "2024-06-11T18:17:26.207646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "modelInstanceId": 28083,
     "sourceId": 33551,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 111.239192,
   "end_time": "2024-06-11T18:17:26.630814",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-11T18:15:35.391622",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
